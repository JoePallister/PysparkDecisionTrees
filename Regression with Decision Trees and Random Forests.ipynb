{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfb51324-1f7a-4138-8e30-f18ce88ad2d9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c48e437-99c2-4569-93ff-2018dcaabfdb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We are interested in applying Decision Trees and Random Forests to regression problems in Spark. Here we are using a dataset with flight data and predicting the length of the delay.\n",
    "\n",
    "We combine our data processing into a pipeline, before training a Decission Tree model and then a Random Forest. Since we are just interested in exploring these models here we do not split out data into train/test sets or evaluate the models, until we look at k-fold cross validation.\n",
    "\n",
    "Finally we look at some simple optimization, where we run the random forest training in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03754d7b-3be1-4d3c-b5e1-c4bcd09d666a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Exploring and tidying the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b385d2db-f2b4-49cd-8c79-95c2a1828d79",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We examine our data and drop most of its many columns. This is to simplify the experiments with the models here, there is almost certainly important information we are losing in the dropped columns. For the same reason we also drop most of the many rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d4b7f74-8870-4160-b98c-41c26b5786ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+------------+------------+\n|Year|Month|DayofMonth|DayOfWeek|DepTime|CRSDepTime|ArrTime|CRSArrTime|UniqueCarrier|FlightNum|TailNum|ActualElapsedTime|CRSElapsedTime|AirTime|ArrDelay|DepDelay|Origin|Dest|Distance|TaxiIn|TaxiOut|Cancelled|CancellationCode|Diverted|CarrierDelay|WeatherDelay|NASDelay|SecurityDelay|LateAircraftDelay|IsArrDelayed|IsDepDelayed|\n+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+------------+------------+\n|1987|   10|        14|        3|    741|       730|    912|       849|           PS|     1451|     NA|               91|            79|     NA|      23|      11|   SAN| SFO|     447|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|         YES|\n|1987|   10|        15|        4|    729|       730|    903|       849|           PS|     1451|     NA|               94|            79|     NA|      14|      -1|   SAN| SFO|     447|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|          NO|\n|1987|   10|        17|        6|    741|       730|    918|       849|           PS|     1451|     NA|               97|            79|     NA|      29|      11|   SAN| SFO|     447|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|         YES|\n|1987|   10|        18|        7|    729|       730|    847|       849|           PS|     1451|     NA|               78|            79|     NA|      -2|      -1|   SAN| SFO|     447|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|          NO|          NO|\n|1987|   10|        19|        1|    749|       730|    922|       849|           PS|     1451|     NA|               93|            79|     NA|      33|      19|   SAN| SFO|     447|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|         YES|\n|1987|   10|        21|        3|    728|       730|    848|       849|           PS|     1451|     NA|               80|            79|     NA|      -1|      -2|   SAN| SFO|     447|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|          NO|          NO|\n|1987|   10|        22|        4|    728|       730|    852|       849|           PS|     1451|     NA|               84|            79|     NA|       3|      -2|   SAN| SFO|     447|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|          NO|\n|1987|   10|        23|        5|    731|       730|    902|       849|           PS|     1451|     NA|               91|            79|     NA|      13|       1|   SAN| SFO|     447|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|         YES|\n|1987|   10|        24|        6|    744|       730|    908|       849|           PS|     1451|     NA|               84|            79|     NA|      19|      14|   SAN| SFO|     447|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|         YES|\n|1987|   10|        25|        7|    729|       730|    851|       849|           PS|     1451|     NA|               82|            79|     NA|       2|      -1|   SAN| SFO|     447|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|          NO|\n|1987|   10|        26|        1|    735|       730|    904|       849|           PS|     1451|     NA|               89|            79|     NA|      15|       5|   SAN| SFO|     447|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|         YES|\n|1987|   10|        28|        3|    741|       725|    919|       855|           PS|     1451|     NA|               98|            90|     NA|      24|      16|   SAN| SFO|     447|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|         YES|\n|1987|   10|        29|        4|    742|       725|    906|       855|           PS|     1451|     NA|               84|            90|     NA|      11|      17|   SAN| SFO|     447|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|         YES|\n|1987|   10|        31|        6|    726|       725|    848|       855|           PS|     1451|     NA|               82|            90|     NA|      -7|       1|   SAN| SFO|     447|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|          NO|         YES|\n|1987|   10|         1|        4|    936|       915|   1035|      1001|           PS|     1451|     NA|               59|            46|     NA|      34|      21|   SFO| RNO|     192|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|         YES|\n|1987|   10|         2|        5|    918|       915|   1017|      1001|           PS|     1451|     NA|               59|            46|     NA|      16|       3|   SFO| RNO|     192|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|         YES|\n|1987|   10|         3|        6|    928|       915|   1037|      1001|           PS|     1451|     NA|               69|            46|     NA|      36|      13|   SFO| RNO|     192|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|         YES|\n|1987|   10|         4|        7|    914|       915|   1003|      1001|           PS|     1451|     NA|               49|            46|     NA|       2|      -1|   SFO| RNO|     192|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|          NO|\n|1987|   10|         5|        1|   1042|       915|   1129|      1001|           PS|     1451|     NA|               47|            46|     NA|      88|      87|   SFO| RNO|     192|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|         YES|\n|1987|   10|         6|        2|    934|       915|   1024|      1001|           PS|     1451|     NA|               50|            46|     NA|      23|      19|   SFO| RNO|     192|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|         YES|\n+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+------------+------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "path = '/databricks-datasets/airlines/part-00000'\n",
    "df = spark.read.option(\"header\", \"true\").csv(path)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7708e9e2-99e1-40f8-80e3-7ce21ae65695",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# We select our columns and drop any NA values as these cause problems for the regression.\n",
    "from pyspark.sql.functions import col\n",
    "reduced = df[['Year', 'Month', 'UniqueCarrier', 'ArrDelay']]\n",
    "reduced = reduced.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b31c48e-9045-4b64-987c-8f4db4ea60ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-------------+--------+\n|Year|Month|UniqueCarrier|ArrDelay|\n+----+-----+-------------+--------+\n|1987|   10|           PS|      23|\n|1987|   10|           PS|      14|\n|1987|   10|           PS|      29|\n|1987|   10|           PS|      -2|\n|1987|   10|           PS|      33|\n+----+-----+-------------+--------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "reduced.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1d80d25-0bb9-4124-9e8f-6558a9f82d54",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Year: string (nullable = true)\n |-- Month: string (nullable = true)\n |-- UniqueCarrier: string (nullable = true)\n |-- ArrDelay: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Looking at the schema we can see that the delay is a string, and we need int.\n",
    "reduced.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21a075dd-9cc0-4d6c-863a-37222d551f03",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "reduced = reduced.select(['Year', 'Month', 'UniqueCarrier', col(\"ArrDelay\").cast('int')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bf3887e-4101-412e-8d8d-b2322d6c5852",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# We take a very small sample of our data to speed things along.\n",
    "reduced = reduced.sample(False, 0.01, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83945472-05e4-4fdf-a057-bcec4d0ff677",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50c3bf45-c44f-40f9-b695-e755ffd00563",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Before running our decision tree model we need to replace any categorical data with indices, using the String Indexer. We also need to combine all feature columns in to one, and we do this with a Vector Assembler. Finally we train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "337edbc6-24e9-4865-a82f-f7f74d555df5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "decTree = DecisionTreeRegressor(labelCol=\"ArrDelay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c96e3045-70df-4bbd-9d69-951baf76bcad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# We need to use the String Indexer for our categorical data. This will replace the categories with indicies depending on frequency (most frequent gets 0, then 1...)\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "catCols = [field for (field, dataType) in reduced.dtypes if dataType == \"string\"]\n",
    "numericCols = []\n",
    "\n",
    "# Name for our columns after they will be indexed\n",
    "indexOutputCols = [x + \"Index\" for x in catCols]\n",
    "\n",
    "stringIndexer = StringIndexer(inputCols=catCols, outputCols=indexOutputCols, handleInvalid=\"skip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3d89a0a-3b44-4dcf-b80a-78ccc38741b9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-------------+--------+---------+----------+------------------+\n|Year|Month|UniqueCarrier|ArrDelay|YearIndex|MonthIndex|UniqueCarrierIndex|\n+----+-----+-------------+--------+---------+----------+------------------+\n|1987|   10|           PS|       2|      0.0|       0.0|              10.0|\n|1987|   10|           PS|      -2|      0.0|       0.0|              10.0|\n|1987|   10|           PS|      -4|      0.0|       0.0|              10.0|\n|1987|   10|           PS|       7|      0.0|       0.0|              10.0|\n|1987|   10|           PS|      10|      0.0|       0.0|              10.0|\n+----+-----+-------------+--------+---------+----------+------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# We can see what the string indexer is doing by fitting it and then transforming the data\n",
    "stringIndexerModel = stringIndexer.fit(dataset=reduced)\n",
    "stringIndexedData = stringIndexerModel.transform(reduced)\n",
    "stringIndexedData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cfb3a60-90cd-4e58-a1ec-328c4c4c1c94",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Our features need to be combined into one column. We do this with a Vector Assembler\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "vecAssembler = VectorAssembler(inputCols=indexOutputCols, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cb7d926-d90b-476d-86ad-7667658e7dc7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-------------+--------+---------+----------+------------------+--------------+\n|Year|Month|UniqueCarrier|ArrDelay|YearIndex|MonthIndex|UniqueCarrierIndex|      features|\n+----+-----+-------------+--------+---------+----------+------------------+--------------+\n|1987|   10|           PS|       2|      0.0|       0.0|              10.0|[0.0,0.0,10.0]|\n|1987|   10|           PS|      -2|      0.0|       0.0|              10.0|[0.0,0.0,10.0]|\n|1987|   10|           PS|      -4|      0.0|       0.0|              10.0|[0.0,0.0,10.0]|\n|1987|   10|           PS|       7|      0.0|       0.0|              10.0|[0.0,0.0,10.0]|\n|1987|   10|           PS|      10|      0.0|       0.0|              10.0|[0.0,0.0,10.0]|\n+----+-----+-------------+--------+---------+----------+------------------+--------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# We can see the effect of this by applying it after the string indexer (as will be done in our pipeline)\n",
    "vecAssembledData = vecAssembler.transform(stringIndexedData)\n",
    "vecAssembledData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98a1201e-cd82-43f2-9b1a-00cb9df03d51",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+\n|      features|ArrDelay|\n+--------------+--------+\n|[0.0,0.0,10.0]|       2|\n|[0.0,0.0,10.0]|      -2|\n|[0.0,0.0,10.0]|      -4|\n|[0.0,0.0,10.0]|       7|\n|[0.0,0.0,10.0]|      10|\n+--------------+--------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# The model will be trained on the new \"features\" column, using it to predict \"ArrDelay\"\n",
    "vecAssembledData['features', 'ArrDelay'].show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14f4e5a3-7721-436f-9751-d9d38411706c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# The model has problems with missing values, so we ensure they are dropped.\n",
    "vecAssembledData = vecAssembledData.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e080ec5-67b7-4a3b-97cc-48bb80152ed2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Finally we fit the model to the two columns from the processed data.\n",
    "decTree = decTree.fit(vecAssembledData['features', 'ArrDelay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "128efb33-f3cd-4683-b64d-8bab0113db7a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressionModel: uid=DecisionTreeRegressor_8b270c3e97ca, depth=5, numNodes=37, numFeatures=3\n  If (feature 2 in {0.0,3.0,5.0,7.0,8.0})\n   If (feature 2 in {3.0,7.0})\n    If (feature 2 in {7.0})\n     Predict: 1.9249394673123488\n    Else (feature 2 not in {7.0})\n     Predict: 2.3701067615658364\n   Else (feature 2 not in {3.0,7.0})\n    If (feature 2 in {8.0})\n     If (feature 1 in {0.0})\n      Predict: 2.8190476190476192\n     Else (feature 1 not in {0.0})\n      Predict: 4.927083333333333\n    Else (feature 2 not in {8.0})\n     If (feature 2 in {0.0})\n      If (feature 1 in {1.0})\n       Predict: 4.147058823529412\n      Else (feature 1 not in {1.0})\n       Predict: 5.11472275334608\n     Else (feature 2 not in {0.0})\n      If (feature 1 in {0.0})\n       Predict: 4.388268156424581\n      Else (feature 1 not in {0.0})\n       Predict: 8.556451612903226\n  Else (feature 2 not in {0.0,3.0,5.0,7.0,8.0})\n   If (feature 2 in {1.0,2.0,4.0,6.0,9.0,11.0,13.0})\n    If (feature 1 in {0.0})\n     If (feature 2 in {1.0,4.0,6.0,9.0,11.0,13.0})\n      If (feature 2 in {1.0,4.0,6.0,9.0,13.0})\n       Predict: 6.687642153146323\n      Else (feature 2 not in {1.0,4.0,6.0,9.0,13.0})\n       Predict: 7.824427480916031\n     Else (feature 2 not in {1.0,4.0,6.0,9.0,11.0,13.0})\n      Predict: 9.612403100775193\n    Else (feature 1 not in {0.0})\n     If (feature 2 in {6.0,11.0})\n      If (feature 2 in {11.0})\n       Predict: 7.610738255033557\n      Else (feature 2 not in {11.0})\n       Predict: 8.63111111111111\n     Else (feature 2 not in {6.0,11.0})\n      If (feature 2 in {1.0})\n       Predict: 10.122093023255815\n      Else (feature 2 not in {1.0})\n       Predict: 11.87557603686636\n   Else (feature 2 not in {1.0,2.0,4.0,6.0,9.0,11.0,13.0})\n    If (feature 1 in {1.0})\n     If (feature 2 in {12.0})\n      Predict: 11.32258064516129\n     Else (feature 2 not in {12.0})\n      Predict: 13.465408805031446\n    Else (feature 1 not in {1.0})\n     If (feature 2 in {10.0})\n      Predict: 16.419117647058822\n     Else (feature 2 not in {10.0})\n      Predict: 18.618181818181817\n\n"
     ]
    }
   ],
   "source": [
    "# We can see the branches of the fitted tree here\n",
    "print(decTree.toDebugString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a338e08-5646-4286-a978-f3c165297a57",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62fce730-10db-4d7d-8349-48625cc89366",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The above process is a little messy, so we compactify it to a Pipeline. This looks like String Indexer -> Vector Assembler -> Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b3f3080-155b-462d-b2ad-d599d4756623",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# We can turn these steps into a pipeline\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "stages = [stringIndexer, vecAssembler, decTree]\n",
    "pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "086722dc-8f82-44c1-ab40-a4bb16fec302",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fit the pipeline to the reduced data\n",
    "reduced = reduced.dropna()\n",
    "pipelineModel = pipeline.fit(reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30821467-9b09-4fa2-b1d9-aaff0c89b724",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressionModel: uid=DecisionTreeRegressor_8b270c3e97ca, depth=5, numNodes=37, numFeatures=3\n  If (feature 2 in {0.0,3.0,5.0,7.0,8.0})\n   If (feature 2 in {3.0,7.0})\n    If (feature 2 in {7.0})\n     Predict: 1.9249394673123488\n    Else (feature 2 not in {7.0})\n     Predict: 2.3701067615658364\n   Else (feature 2 not in {3.0,7.0})\n    If (feature 2 in {8.0})\n     If (feature 1 in {0.0})\n      Predict: 2.8190476190476192\n     Else (feature 1 not in {0.0})\n      Predict: 4.927083333333333\n    Else (feature 2 not in {8.0})\n     If (feature 2 in {0.0})\n      If (feature 1 in {1.0})\n       Predict: 4.147058823529412\n      Else (feature 1 not in {1.0})\n       Predict: 5.11472275334608\n     Else (feature 2 not in {0.0})\n      If (feature 1 in {0.0})\n       Predict: 4.388268156424581\n      Else (feature 1 not in {0.0})\n       Predict: 8.556451612903226\n  Else (feature 2 not in {0.0,3.0,5.0,7.0,8.0})\n   If (feature 2 in {1.0,2.0,4.0,6.0,9.0,11.0,13.0})\n    If (feature 1 in {0.0})\n     If (feature 2 in {1.0,4.0,6.0,9.0,11.0,13.0})\n      If (feature 2 in {1.0,4.0,6.0,9.0,13.0})\n       Predict: 6.687642153146323\n      Else (feature 2 not in {1.0,4.0,6.0,9.0,13.0})\n       Predict: 7.824427480916031\n     Else (feature 2 not in {1.0,4.0,6.0,9.0,11.0,13.0})\n      Predict: 9.612403100775193\n    Else (feature 1 not in {0.0})\n     If (feature 2 in {6.0,11.0})\n      If (feature 2 in {11.0})\n       Predict: 7.610738255033557\n      Else (feature 2 not in {11.0})\n       Predict: 8.63111111111111\n     Else (feature 2 not in {6.0,11.0})\n      If (feature 2 in {1.0})\n       Predict: 10.122093023255815\n      Else (feature 2 not in {1.0})\n       Predict: 11.87557603686636\n   Else (feature 2 not in {1.0,2.0,4.0,6.0,9.0,11.0,13.0})\n    If (feature 1 in {1.0})\n     If (feature 2 in {12.0})\n      Predict: 11.32258064516129\n     Else (feature 2 not in {12.0})\n      Predict: 13.465408805031446\n    Else (feature 1 not in {1.0})\n     If (feature 2 in {10.0})\n      Predict: 16.419117647058822\n     Else (feature 2 not in {10.0})\n      Predict: 18.618181818181817\n\n"
     ]
    }
   ],
   "source": [
    "dtModel = pipelineModel.stages[-1]\n",
    "print(dtModel.toDebugString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d460c211-7364-4a7f-8a24-9c88efcf3644",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3efd1e33-1a40-4580-ab32-11973b9606b6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Random forest regression involves running multiple Decision Trees and then averaging the result, thus providing a more robust prediction. We can run this using the same pipeline as above as the input data is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0212eab-2271-4731-b4a6-3caccc1710c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Let's try the same but with a Random Forest\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "rf = RandomForestRegressor(labelCol=\"ArrDelay\", maxBins=40, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d0f997c-ae11-4355-af95-4b81d9637960",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# The pipeline is the same here\n",
    "stages = [stringIndexer, vecAssembler, rf]\n",
    "pipeline = Pipeline(stages=stages)\n",
    "pipelineModel = pipeline.fit(reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43bc4a4b-89a9-41a5-879b-c3bb3aeff694",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressionModel: uid=RandomForestRegressor_3e7553bb556c, numTrees=20, numFeatures=3\n  Tree 0 (weight 1.0):\n    If (feature 2 in {0.0,3.0,5.0,7.0,8.0,11.0,13.0})\n     Predict: 4.153821757056772\n    Else (feature 2 not in {0.0,3.0,5.0,7.0,8.0,11.0,13.0})\n     If (feature 1 in {0.0})\n      If (feature 2 in {1.0,2.0,4.0,6.0,9.0})\n       Predict: 8.032848680667744\n      Else (feature 2 not in {1.0,2.0,4.0,6.0,9.0})\n       Predict: 17.271186440677965\n     Else (feature 1 not in {0.0})\n      If (feature 2 in {6.0,12.0})\n       If (feature 2 in {6.0})\n        Predict: 8.038461538461538\n       Else (feature 2 not in {6.0})\n        Predict: 8.615384615384615\n      Else (feature 2 not in {6.0,12.0})\n       Predict: 11.673825503355705\n  Tree 1 (weight 1.0):\n    If (feature 2 in {0.0,3.0,7.0,8.0})\n     Predict: 3.485424588086185\n    Else (feature 2 not in {0.0,3.0,7.0,8.0})\n     If (feature 1 in {0.0})\n      Predict: 7.853891336270191\n     Else (feature 1 not in {0.0})\n      Predict: 10.347959969207082\n  Tree 2 (weight 1.0):\n    If (feature 2 in {0.0,3.0,5.0,7.0,8.0})\n     If (feature 1 in {0.0})\n      Predict: 3.2965284474445515\n     Else (feature 1 not in {0.0})\n      If (feature 2 in {0.0,8.0})\n       Predict: 4.405970149253731\n      Else (feature 2 not in {0.0,8.0})\n       Predict: 7.257142857142857\n    Else (feature 2 not in {0.0,3.0,5.0,7.0,8.0})\n     Predict: 9.79322429906542\n  Tree 3 (weight 1.0):\n    If (feature 2 in {0.0,3.0,5.0,7.0,8.0})\n     Predict: 3.3124779073877697\n    Else (feature 2 not in {0.0,3.0,5.0,7.0,8.0})\n     Predict: 9.256872852233677\n  Tree 4 (weight 1.0):\n    If (feature 2 in {0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,13.0})\n     Predict: 6.589036652611093\n    Else (feature 2 not in {0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,13.0})\n     Predict: 26.169117647058822\n  Tree 5 (weight 1.0):\n    If (feature 2 in {0.0,3.0,7.0,8.0})\n     Predict: 2.933219178082192\n    Else (feature 2 not in {0.0,3.0,7.0,8.0})\n     If (feature 1 in {0.0})\n      Predict: 7.904761904761905\n     Else (feature 1 not in {0.0})\n      Predict: 10.702599388379205\n  Tree 6 (weight 1.0):\n    Predict: 6.703380588876772\n  Tree 7 (weight 1.0):\n    If (feature 2 in {0.0,3.0,5.0,7.0,8.0,13.0})\n     If (feature 1 in {0.0})\n      Predict: 3.233940556088207\n     Else (feature 1 not in {0.0})\n      If (feature 2 in {0.0,8.0})\n       Predict: 3.422360248447205\n      Else (feature 2 not in {0.0,8.0})\n       Predict: 5.067226890756302\n    Else (feature 2 not in {0.0,3.0,5.0,7.0,8.0,13.0})\n     If (feature 2 in {1.0,2.0,4.0,6.0,9.0,11.0})\n      If (feature 1 in {0.0})\n       Predict: 7.869879518072289\n      Else (feature 1 not in {0.0})\n       Predict: 9.922246220302377\n     Else (feature 2 not in {1.0,2.0,4.0,6.0,9.0,11.0})\n      If (feature 1 in {0.0})\n       Predict: 12.481081081081081\n      Else (feature 1 not in {0.0})\n       Predict: 13.27927927927928\n  Tree 8 (weight 1.0):\n    If (feature 2 in {0.0,3.0,5.0,7.0,8.0})\n     Predict: 3.8180218233016543\n    Else (feature 2 not in {0.0,3.0,5.0,7.0,8.0})\n     Predict: 9.263083451202263\n  Tree 9 (weight 1.0):\n    If (feature 1 in {0.0})\n     Predict: 6.29255079006772\n    Else (feature 1 not in {0.0})\n     Predict: 8.359533468559837\n  Tree 10 (weight 1.0):\n    If (feature 1 in {0.0})\n     Predict: 5.58092819210344\n    Else (feature 1 not in {0.0})\n     Predict: 7.755544094894275\n  Tree 11 (weight 1.0):\n    If (feature 2 in {0.0,3.0,7.0,8.0})\n     Predict: 3.3784794349813043\n    Else (feature 2 not in {0.0,3.0,7.0,8.0})\n     If (feature 1 in {0.0})\n      If (feature 2 in {1.0,2.0,4.0,5.0,6.0,9.0,11.0,12.0,13.0})\n       Predict: 7.666535277887268\n      Else (feature 2 not in {1.0,2.0,4.0,5.0,6.0,9.0,11.0,12.0,13.0})\n       Predict: 17.2\n     Else (feature 1 not in {0.0})\n      Predict: 9.427363566487317\n  Tree 12 (weight 1.0):\n    If (feature 1 in {0.0})\n     Predict: 5.755863039399625\n    Else (feature 1 not in {0.0})\n     If (feature 2 in {0.0,6.0,8.0,11.0,12.0})\n      Predict: 6.759082217973232\n     Else (feature 2 not in {0.0,6.0,8.0,11.0,12.0})\n      Predict: 11.137809187279151\n  Tree 13 (weight 1.0):\n    Predict: 7.184202211690363\n  Tree 14 (weight 1.0):\n    Predict: 6.584189723320158\n  Tree 15 (weight 1.0):\n    If (feature 2 in {0.0,3.0,5.0,6.0,7.0,8.0,13.0})\n     If (feature 2 in {3.0,7.0,8.0})\n      If (feature 2 in {7.0})\n       Predict: 1.3181818181818181\n      Else (feature 2 not in {7.0})\n       Predict: 2.8018672199170123\n     Else (feature 2 not in {3.0,7.0,8.0})\n      If (feature 2 in {5.0,13.0})\n       If (feature 1 in {0.0})\n        Predict: 4.173333333333333\n       Else (feature 1 not in {0.0})\n        Predict: 8.68840579710145\n      Else (feature 2 not in {5.0,13.0})\n       Predict: 5.88929889298893\n    Else (feature 2 not in {0.0,3.0,5.0,6.0,7.0,8.0,13.0})\n     If (feature 1 in {0.0})\n      Predict: 8.190858864892014\n     Else (feature 1 not in {0.0})\n      Predict: 11.033578174186779\n  Tree 16 (weight 1.0):\n    Predict: 6.639980513153621\n  Tree 17 (weight 1.0):\n    If (feature 1 in {0.0})\n     If (feature 2 in {0.0,1.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,12.0,13.0})\n      Predict: 4.502321532211259\n     Else (feature 2 not in {0.0,1.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,12.0,13.0})\n      Predict: 10.73421926910299\n    Else (feature 1 not in {0.0})\n     Predict: 7.977475117862755\n  Tree 18 (weight 1.0):\n    If (feature 2 in {0.0,3.0,5.0,7.0,8.0,13.0})\n     Predict: 3.9262406526172673\n    Else (feature 2 not in {0.0,3.0,5.0,7.0,8.0,13.0})\n     If (feature 1 in {0.0})\n      If (feature 2 in {1.0,2.0,4.0,6.0,9.0,11.0,12.0})\n       If (feature 2 in {4.0})\n        Predict: 5.391812865497076\n       Else (feature 2 not in {4.0})\n        Predict: 8.367287543655413\n      Else (feature 2 not in {1.0,2.0,4.0,6.0,9.0,11.0,12.0})\n       Predict: 15.645390070921986\n     Else (feature 1 not in {0.0})\n      Predict: 9.118689105403012\n  Tree 19 (weight 1.0):\n    If (feature 2 in {3.0,5.0,7.0,8.0})\n     If (feature 2 in {3.0,7.0})\n      Predict: 0.12\n     Else (feature 2 not in {3.0,7.0})\n      If (feature 2 in {8.0})\n       Predict: 3.6533018867924527\n      Else (feature 2 not in {8.0})\n       Predict: 4.299586776859504\n    Else (feature 2 not in {3.0,5.0,7.0,8.0})\n     Predict: 8.063022362773888\n\n"
     ]
    }
   ],
   "source": [
    "# Look at tree branches\n",
    "rfModel = pipelineModel.stages[-1]\n",
    "print(rfModel.toDebugString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4324f15c-cf7f-4ec5-8d39-decbce5449b4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Hyperparameter Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "074c2d53-ce1a-497d-bbd2-b74a7f2754fc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Here we perform a grid search to find the best pair of parameters (max depth and number of trees) for our forest. We use the ParamGridBuilder to construct a grid from our possible choice of parameters (here 2 x 3 giving 6 possibilities). We use the regression evaluator with the RMSE metric to find the best pair, which is performed using k-fold cross validation (here k=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f3ba05e-8c47-4f5d-9b3b-46f05e39a8d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# We want to find the best hyperparameters. For example we can search over the following grid, where we allow max depth to be 2,4 or 6 and the number of trees to be 10 or 100\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "paramGrid = (ParamGridBuilder()\n",
    " .addGrid(rf.maxDepth, [2, 4, 6])\n",
    " .addGrid(rf.numTrees, [10, 100])\n",
    " .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4fb6664-3bf2-425e-9eff-fc2f459d81c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# To evaluate each of the hyperparameter pairs we use a regression evaulator with RMSE\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(labelCol=\"ArrDelay\",\n",
    " predictionCol=\"prediction\",\n",
    " metricName=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5e814cf-051b-49e6-bbd9-b039edc516b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Finally we use k-fold (with k=3) cross validation to evaluate each of the hyperparameter combinations\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "cv = CrossValidator(estimator=pipeline,\n",
    " evaluator=evaluator,\n",
    " estimatorParamMaps=paramGrid,\n",
    " numFolds=3,\n",
    " seed=42)\n",
    "cvModel = cv.fit(reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "292f06e6-fd1b-4141-97bb-aa156abfd8b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[175]: [({Param(parent='RandomForestRegressor_3e7553bb556c', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 2,\n   Param(parent='RandomForestRegressor_3e7553bb556c', name='numTrees', doc='Number of trees to train (>= 1).'): 10},\n  20.560019694881976),\n ({Param(parent='RandomForestRegressor_3e7553bb556c', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 2,\n   Param(parent='RandomForestRegressor_3e7553bb556c', name='numTrees', doc='Number of trees to train (>= 1).'): 100},\n  20.56852718605279),\n ({Param(parent='RandomForestRegressor_3e7553bb556c', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 4,\n   Param(parent='RandomForestRegressor_3e7553bb556c', name='numTrees', doc='Number of trees to train (>= 1).'): 10},\n  20.54844245597304),\n ({Param(parent='RandomForestRegressor_3e7553bb556c', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 4,\n   Param(parent='RandomForestRegressor_3e7553bb556c', name='numTrees', doc='Number of trees to train (>= 1).'): 100},\n  20.55820000349847),\n ({Param(parent='RandomForestRegressor_3e7553bb556c', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 6,\n   Param(parent='RandomForestRegressor_3e7553bb556c', name='numTrees', doc='Number of trees to train (>= 1).'): 10},\n  20.548298964281283),\n ({Param(parent='RandomForestRegressor_3e7553bb556c', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 6,\n   Param(parent='RandomForestRegressor_3e7553bb556c', name='numTrees', doc='Number of trees to train (>= 1).'): 100},\n  20.55830469047292)]"
     ]
    }
   ],
   "source": [
    "# We can see the performance here. There is little difference, suggesting our choice of grid needs to be enlarged or changed entirely.\n",
    "list(zip(cvModel.getEstimatorParamMaps(), cvModel.avgMetrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c78b27d4-0ad3-4833-be22-1a41e814bc3f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79a97fd2-8c32-488d-9951-1d27003fe44d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Here we look at two ways to improve the speed of the above model training. Since the Random Forest models are independet, we can train them in parallel, doing which saves some time. We also note that, above, the cross validator is performing the String Indexinger and Vector Assembler on each fold and for each pair of parameters. By moving these before the cross validator we can also save some time  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74ef2e80-c765-490f-a21c-7bb17de87392",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Try training the forests in the CV model parallel\n",
    "cvModel = cv.setParallelism(4).fit(reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af65e598-ca68-4da5-9ca6-506fe89e8d34",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Reorganise the pipeline to perform string indexing and vector assembling first\n",
    "cv = CrossValidator(estimator=rf,\n",
    " evaluator=evaluator,\n",
    " estimatorParamMaps=paramGrid,\n",
    " numFolds=3,\n",
    " parallelism=4,\n",
    " seed=42)\n",
    "pipeline = Pipeline(stages=[stringIndexer, vecAssembler, cv])\n",
    "pipelineModel = pipeline.fit(reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "780f3f7f-a6ea-4873-bb35-1caa706c507c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[178]: [({Param(parent='RandomForestRegressor_3e7553bb556c', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 2,\n   Param(parent='RandomForestRegressor_3e7553bb556c', name='numTrees', doc='Number of trees to train (>= 1).'): 10},\n  20.560019694881976),\n ({Param(parent='RandomForestRegressor_3e7553bb556c', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 2,\n   Param(parent='RandomForestRegressor_3e7553bb556c', name='numTrees', doc='Number of trees to train (>= 1).'): 100},\n  20.56852718605279),\n ({Param(parent='RandomForestRegressor_3e7553bb556c', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 4,\n   Param(parent='RandomForestRegressor_3e7553bb556c', name='numTrees', doc='Number of trees to train (>= 1).'): 10},\n  20.54844245597304),\n ({Param(parent='RandomForestRegressor_3e7553bb556c', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 4,\n   Param(parent='RandomForestRegressor_3e7553bb556c', name='numTrees', doc='Number of trees to train (>= 1).'): 100},\n  20.55820000349847),\n ({Param(parent='RandomForestRegressor_3e7553bb556c', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 6,\n   Param(parent='RandomForestRegressor_3e7553bb556c', name='numTrees', doc='Number of trees to train (>= 1).'): 10},\n  20.548298964281283),\n ({Param(parent='RandomForestRegressor_3e7553bb556c', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 6,\n   Param(parent='RandomForestRegressor_3e7553bb556c', name='numTrees', doc='Number of trees to train (>= 1).'): 100},\n  20.55830469047292)]"
     ]
    }
   ],
   "source": [
    "list(zip(cvModel.getEstimatorParamMaps(), cvModel.avgMetrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4651685e-dd63-40e9-99e5-015abc416e59",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Regression with Decision Trees and Random Forests",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

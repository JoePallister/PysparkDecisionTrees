{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "660aaf8e-7654-41cd-9df5-91789820ad9f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bd82ffd-4109-40cd-9aa5-f39e6ba8c65a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We are interested in applying Decision Trees and Random Forests to binary classification problems in Spark. Here we are using a dataset with flight data and predicting if a flight is cancelled or not. Of course, this data set is not balanced, as most flights are not cancelled. For the same of the exercise we reduce the dataset so that we have approximately 50% of the flight cancelled.\n",
    "\n",
    "We combine our data processing into a pipeline, before training a Decision Tree model and then a Random Forest. Since we are just interested in exploring these models here we do not split out data into train/test sets or evaluate the models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "118e47db-f576-4cc7-b9ef-683928974918",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Exploring and tidying the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98738618-9e81-4a39-8577-ddf3597b930d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We explore the data and note that we have many more uncancelled flights than cancelled. We resample the data to get a balanced data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1aec24c0-99cd-40db-9460-be528b3ab725",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/databricks-datasets/COVID/</td><td>COVID/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/README.md</td><td>README.md</td><td>976</td><td>1532468253000</td></tr><tr><td>dbfs:/databricks-datasets/Rdatasets/</td><td>Rdatasets/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/SPARK_README.md</td><td>SPARK_README.md</td><td>3359</td><td>1455043490000</td></tr><tr><td>dbfs:/databricks-datasets/adult/</td><td>adult/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/airlines/</td><td>airlines/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/amazon/</td><td>amazon/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/asa/</td><td>asa/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/atlas_higgs/</td><td>atlas_higgs/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/bikeSharing/</td><td>bikeSharing/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/cctvVideos/</td><td>cctvVideos/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/credit-card-fraud/</td><td>credit-card-fraud/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/cs100/</td><td>cs100/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/cs110x/</td><td>cs110x/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/cs190/</td><td>cs190/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/data.gov/</td><td>data.gov/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/definitive-guide/</td><td>definitive-guide/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/delta-sharing/</td><td>delta-sharing/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/flights/</td><td>flights/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/flower_photos/</td><td>flower_photos/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/flowers/</td><td>flowers/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/genomics/</td><td>genomics/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/hail/</td><td>hail/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/identifying-campaign-effectiveness/</td><td>identifying-campaign-effectiveness/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/iot/</td><td>iot/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/iot-stream/</td><td>iot-stream/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/learning-spark/</td><td>learning-spark/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/learning-spark-v2/</td><td>learning-spark-v2/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/lending-club-loan-stats/</td><td>lending-club-loan-stats/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/med-images/</td><td>med-images/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/media/</td><td>media/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/mnist-digits/</td><td>mnist-digits/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/news20.binary/</td><td>news20.binary/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/nyctaxi/</td><td>nyctaxi/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/nyctaxi-with-zipcodes/</td><td>nyctaxi-with-zipcodes/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/online_retail/</td><td>online_retail/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/overlap-join/</td><td>overlap-join/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/power-plant/</td><td>power-plant/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/retail-org/</td><td>retail-org/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/rwe/</td><td>rwe/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/sai-summit-2019-sf/</td><td>sai-summit-2019-sf/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/sample_logs/</td><td>sample_logs/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/samples/</td><td>samples/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/sfo_customer_survey/</td><td>sfo_customer_survey/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/sms_spam_collection/</td><td>sms_spam_collection/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/songs/</td><td>songs/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/structured-streaming/</td><td>structured-streaming/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/timeseries/</td><td>timeseries/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/tpch/</td><td>tpch/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/travel_recommendations_realtime/</td><td>travel_recommendations_realtime/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/warmup/</td><td>warmup/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/weather/</td><td>weather/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/wiki/</td><td>wiki/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/wikipedia-datasets/</td><td>wikipedia-datasets/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/wine-quality/</td><td>wine-quality/</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/databricks-datasets/COVID/",
         "COVID/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/README.md",
         "README.md",
         976,
         1532468253000
        ],
        [
         "dbfs:/databricks-datasets/Rdatasets/",
         "Rdatasets/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/SPARK_README.md",
         "SPARK_README.md",
         3359,
         1455043490000
        ],
        [
         "dbfs:/databricks-datasets/adult/",
         "adult/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/airlines/",
         "airlines/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/amazon/",
         "amazon/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/asa/",
         "asa/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/atlas_higgs/",
         "atlas_higgs/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/bikeSharing/",
         "bikeSharing/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/cctvVideos/",
         "cctvVideos/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/credit-card-fraud/",
         "credit-card-fraud/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/cs100/",
         "cs100/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/cs110x/",
         "cs110x/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/cs190/",
         "cs190/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/data.gov/",
         "data.gov/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/definitive-guide/",
         "definitive-guide/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/delta-sharing/",
         "delta-sharing/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/flights/",
         "flights/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/flower_photos/",
         "flower_photos/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/flowers/",
         "flowers/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/genomics/",
         "genomics/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/hail/",
         "hail/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/identifying-campaign-effectiveness/",
         "identifying-campaign-effectiveness/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/iot/",
         "iot/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/iot-stream/",
         "iot-stream/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/learning-spark/",
         "learning-spark/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/learning-spark-v2/",
         "learning-spark-v2/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/lending-club-loan-stats/",
         "lending-club-loan-stats/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/med-images/",
         "med-images/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/media/",
         "media/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/mnist-digits/",
         "mnist-digits/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/news20.binary/",
         "news20.binary/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/nyctaxi/",
         "nyctaxi/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/nyctaxi-with-zipcodes/",
         "nyctaxi-with-zipcodes/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/online_retail/",
         "online_retail/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/overlap-join/",
         "overlap-join/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/power-plant/",
         "power-plant/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/retail-org/",
         "retail-org/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/rwe/",
         "rwe/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/sai-summit-2019-sf/",
         "sai-summit-2019-sf/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/sample_logs/",
         "sample_logs/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/samples/",
         "samples/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/sfo_customer_survey/",
         "sfo_customer_survey/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/sms_spam_collection/",
         "sms_spam_collection/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/songs/",
         "songs/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/structured-streaming/",
         "structured-streaming/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/timeseries/",
         "timeseries/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/tpch/",
         "tpch/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/travel_recommendations_realtime/",
         "travel_recommendations_realtime/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/warmup/",
         "warmup/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/weather/",
         "weather/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/wiki/",
         "wiki/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/wikipedia-datasets/",
         "wikipedia-datasets/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/wine-quality/",
         "wine-quality/",
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show available datasets\n",
    "display(dbutils.fs.ls('/databricks-datasets'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cd6df35-818a-4803-8868-eeba0feab146",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/databricks-datasets/airlines/part-00000</td><td>part-00000</td><td>67108879</td><td>1436493184000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/databricks-datasets/airlines/part-00000",
         "part-00000",
         67108879,
         1436493184000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dbutils.fs.ls('/databricks-datasets/airlines/part-00000'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5dfc90dc-449f-4787-bb5b-4e8fc16d70e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+------------+------------+\n|Year|Month|DayofMonth|DayOfWeek|DepTime|CRSDepTime|ArrTime|CRSArrTime|UniqueCarrier|FlightNum|TailNum|ActualElapsedTime|CRSElapsedTime|AirTime|ArrDelay|DepDelay|Origin|Dest|Distance|TaxiIn|TaxiOut|Cancelled|CancellationCode|Diverted|CarrierDelay|WeatherDelay|NASDelay|SecurityDelay|LateAircraftDelay|IsArrDelayed|IsDepDelayed|\n+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+------------+------------+\n|1987|   10|        14|        3|    741|       730|    912|       849|           PS|     1451|     NA|               91|            79|     NA|      23|      11|   SAN| SFO|     447|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|         YES|\n|1987|   10|        15|        4|    729|       730|    903|       849|           PS|     1451|     NA|               94|            79|     NA|      14|      -1|   SAN| SFO|     447|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|          NO|\n|1987|   10|        17|        6|    741|       730|    918|       849|           PS|     1451|     NA|               97|            79|     NA|      29|      11|   SAN| SFO|     447|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|         YES|\n|1987|   10|        18|        7|    729|       730|    847|       849|           PS|     1451|     NA|               78|            79|     NA|      -2|      -1|   SAN| SFO|     447|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|          NO|          NO|\n|1987|   10|        19|        1|    749|       730|    922|       849|           PS|     1451|     NA|               93|            79|     NA|      33|      19|   SAN| SFO|     447|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|         YES|\n+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+------------+------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "path = '/databricks-datasets/airlines/part-00000'\n",
    "df = spark.read.option(\"header\", \"true\").csv(path)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26e8ef10-96e4-4e45-bc55-b3f402a0994b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[26]: 0.008062401678028316"
     ]
    }
   ],
   "source": [
    "# We can see that very few flights are cancelled. This will lead to difficulty with predictions, as we can trivially predict all flights not to be cancelled and be almost always correct.\n",
    "# We will change the data to something more suitable for the experiments below, but of course we shouldn't do this with real data.\n",
    "cancelled_ratio = df.filter(df['Cancelled'] == 1).count() / df.filter(df['Cancelled'] == 0).count()\n",
    "cancelled_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38d54b25-d671-40c3-b397-2669ac0bc727",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cancelled = df.filter(df['Cancelled'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "815520d5-f124-49be-a5da-2fb902ffcc20",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# We take a sample of the non-cancelled data so that we have approximately the same number of cancelled and non-cancelled flights\n",
    "non_cancelled_sample = df.filter(df['Cancelled'] == 0).sample(False, cancelled_ratio, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11d255d5-47a9-44cd-8821-8038df4bf2c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[29]: 0.9796747967479674"
     ]
    }
   ],
   "source": [
    "# Now we can see we have approximately the same cancelled and non-cancelled\n",
    "non_cancelled_sample.count() / cancelled.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d05c807-6674-48a2-ba40-040c1e8d4a16",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+------------+------------+\n|Year|Month|DayofMonth|DayOfWeek|DepTime|CRSDepTime|ArrTime|CRSArrTime|UniqueCarrier|FlightNum|TailNum|ActualElapsedTime|CRSElapsedTime|AirTime|ArrDelay|DepDelay|Origin|Dest|Distance|TaxiIn|TaxiOut|Cancelled|CancellationCode|Diverted|CarrierDelay|WeatherDelay|NASDelay|SecurityDelay|LateAircraftDelay|IsArrDelayed|IsDepDelayed|\n+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+------------+------------+\n|1987|   10|        25|        7|    729|       730|    851|       849|           PS|     1451|     NA|               82|            79|     NA|       2|      -1|   SAN| SFO|     447|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|          NO|\n|1987|   10|        16|        5|   1124|      1120|   1254|      1250|           PS|     1459|     NA|               90|            90|     NA|       4|       4|   SFO| PDX|     550|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|         YES|\n|1987|   10|        13|        2|   1958|      2000|   2101|      2059|           PS|     1465|     NA|               63|            59|     NA|       2|      -2|   BUR| OAK|     325|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|          NO|\n|1987|   10|        27|        2|   1628|      1628|   1754|      1745|           PS|     1476|     NA|               86|            77|     NA|       9|       0|   OAK| SAN|     446|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|          NO|\n|1987|   10|        12|        1|   1842|      1830|   1958|      1936|           PS|     1477|     NA|               76|            66|     NA|      22|      12|   LAX| SFO|     337|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|         YES|\n|1987|   10|        28|        3|   1137|      1134|   1233|      1232|           PS|     1490|     NA|               56|            58|     NA|       1|       3|   SNA| LAS|     226|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|         YES|\n|1987|   10|        27|        2|   1712|      1710|   1831|      1824|           PS|     1491|     NA|               79|            74|     NA|       7|       2|   SNA| OAK|     371|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|         YES|\n|1987|   10|        29|        4|    629|       630|    754|       745|           PS|     1492|     NA|               85|            75|     NA|       9|      -1|   OAK| SNA|     371|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|          NO|\n|1987|   10|        29|        4|   1322|      1318|   1436|      1430|           PS|     1494|     NA|               74|            72|     NA|       6|       4|   OAK| SNA|     371|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|         YES|\n|1987|   10|         7|        3|    711|       710|    800|       801|           PS|     1512|     NA|               49|            51|     NA|      -1|       1|   LAX| LAS|     236|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|          NO|         YES|\n|1987|   10|        21|        3|    659|       700|    809|       807|           PS|     1517|     NA|               70|            67|     NA|       2|      -1|   LAX| SFO|     337|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|          NO|\n|1987|   10|        13|        2|   1129|      1130|   1234|      1234|           PS|     1524|     NA|               65|            64|     NA|       0|      -1|   SFO| BUR|     326|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|          NO|          NO|\n|1987|   10|        25|        7|   1803|      1800|   1929|      1911|           PS|     1526|     NA|               86|            71|     NA|      18|       3|   SFO| LAX|     337|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|         YES|\n|1987|   10|        30|        5|   1759|      1800|   1920|      1913|           PS|     1526|     NA|               81|            73|     NA|       7|      -1|   SFO| LAX|     337|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|          NO|\n|1987|   10|         8|        4|   1831|      1830|   1935|      1931|           PS|     1538|     NA|               64|            61|     NA|       4|       1|   SFO| BUR|     326|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|         YES|\n|1987|   10|        17|        6|    631|       630|    728|       723|           PS|     1546|     NA|               57|            53|     NA|       5|       1|   SJC| BUR|     296|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|         YES|\n|1987|   10|        24|        6|   1945|      1946|   2038|      2034|           PS|     1564|     NA|               53|            48|     NA|       4|      -1|   BUR| LAS|     223|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|          NO|\n|1987|   10|         1|        4|   1750|      1730|   1900|      1833|           PS|     1575|     NA|               70|            63|     NA|      27|      20|   LAX| SFO|     337|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|         YES|\n|1987|   10|        25|        7|   1752|      1730|   1853|      1833|           PS|     1575|     NA|               61|            63|     NA|      20|      22|   LAX| SFO|     337|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|         YES|         YES|\n|1987|   10|         5|        1|    625|       625|    743|       744|           PS|     1581|     NA|               78|            79|     NA|      -1|       0|   SAN| SMF|     480|    NA|     NA|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|          NO|          NO|\n+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+------------+------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# We now rejoin the data\n",
    "balanced_data = non_cancelled_sample.union(cancelled)\n",
    "balanced_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf696708-7e1e-4376-8e91-6e304b339271",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Now that we have balanced data we select only the columns we want.\n",
    "reduced = balanced_data[['Year', 'Month', 'UniqueCarrier', 'Cancelled']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1df1e920-f2dc-4639-b8c9-b838ec28bc1b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-------------+---------+\n|Year|Month|UniqueCarrier|Cancelled|\n+----+-----+-------------+---------+\n|1987|   10|           PS|        0|\n|1987|   10|           PS|        0|\n|1987|   10|           PS|        0|\n|1987|   10|           PS|        0|\n|1987|   10|           PS|        0|\n+----+-----+-------------+---------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "reduced.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a27a097-a4bb-4138-8635-c26df109227c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# We will have problems with the Decision Tree if we have NA\n",
    "reduced = reduced.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "534d1760-e514-49ff-8aea-e8978c127757",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd7eaf43-3cc6-44a5-9d98-ed1b84e81138",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We process our data by recasting our \"Cancelled\" column as int, using the String Indexer to replace categorical data with indices, and pass to the Vector Assembler to combine all features in one vector. We combine these into a pipeline and fit it to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b0d36ee-df8c-4d0e-9464-bc625bc16f54",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dec_tree = DecisionTreeClassifier(labelCol=\"Cancelled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be74706f-f027-4a68-943d-3edc119c6b72",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Year: string (nullable = true)\n |-- Month: string (nullable = true)\n |-- UniqueCarrier: string (nullable = true)\n |-- Cancelled: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "reduced.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83e16488-9a2c-45d1-af51-eda81a9443e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cancelled needs to be numerical for Decision Tree\n",
    "from pyspark.sql.functions import col\n",
    "reduced = reduced.select(['Year', 'Month', 'UniqueCarrier', col('Cancelled').cast('int')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f45e88e8-951f-4dde-8b0a-e913c5385b7d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# We need to use the String Indexer for our categorical data\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "catCols = [field for (field, dataType) in reduced.dtypes if dataType == \"string\"]\n",
    "numericCols = []\n",
    "\n",
    "# Name for our columns after they will be indexed\n",
    "indexOutputCols = [x + \"Index\" for x in catCols]\n",
    "\n",
    "str_indexer = StringIndexer(inputCols=catCols, outputCols=indexOutputCols, handleInvalid='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "160b6ef1-8c13-49ad-a1c7-a09c19735889",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Finally we pass all inputs to the Vector Assembler\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assemblerInputs = indexOutputCols + numericCols\n",
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad58dd9e-d14d-4385-89bd-8d02a7cb5358",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# We can turn this to a pipeline\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "stages = [str_indexer, vecAssembler, dec_tree]\n",
    "pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87b0d76b-d0c5-40fb-b561-5c36aa791f84",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fit the pipeline to the reduced data\n",
    "pipelineModel = pipeline.fit(reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9ab9fb0-dd30-4a42-a3be-8cfa855f1a3b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_55fd76276d3b, depth=5, numNodes=15, numClasses=2, numFeatures=3\n  If (feature 2 in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n   If (feature 2 in {5.0,6.0,9.0,10.0,11.0,12.0,13.0})\n    If (feature 2 in {13.0})\n     Predict: 1.0\n    Else (feature 2 not in {13.0})\n     If (feature 1 in {1.0})\n      If (feature 2 in {12.0})\n       Predict: 1.0\n      Else (feature 2 not in {12.0})\n       Predict: 0.0\n     Else (feature 1 not in {1.0})\n      Predict: 0.0\n   Else (feature 2 not in {5.0,6.0,9.0,10.0,11.0,12.0,13.0})\n    If (feature 1 in {1.0})\n     Predict: 1.0\n    Else (feature 1 not in {1.0})\n     If (feature 2 in {7.0,8.0})\n      Predict: 1.0\n     Else (feature 2 not in {7.0,8.0})\n      Predict: 0.0\n  Else (feature 2 not in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n   Predict: 1.0\n\n"
     ]
    }
   ],
   "source": [
    "# We can see the Tree's branches and predictions\n",
    "dtModel = pipelineModel.stages[-1]\n",
    "print(dtModel.toDebugString)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ab36940-0b9b-4f79-9615-9978519c4202",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Random Forest Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3afcdd39-13ea-4132-916c-3e5f38987b17",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Now we try a Random Forest classifier. Luckily we can use the same pipeline defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "594b812a-7aff-4a09-a264-b1b2ddb9e94e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Let's try the same but with a Random Forest\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"Cancelled\", maxBins=40, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8595e943-c644-429e-a9b2-f4f53d04ebce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# The pipeline is the same here\n",
    "stages = [str_indexer, vecAssembler, rf]\n",
    "pipeline = Pipeline(stages=stages)\n",
    "pipelineModel = pipeline.fit(reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b78e62bf-7197-4ad3-a46b-3599a0ff3629",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassificationModel: uid=RandomForestClassifier_61d0bc3e5c78, numTrees=20, numClasses=2, numFeatures=3\n  Tree 0 (weight 1.0):\n    If (feature 1 in {1.0})\n     Predict: 1.0\n    Else (feature 1 not in {1.0})\n     If (feature 2 in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n      Predict: 0.0\n     Else (feature 2 not in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n      Predict: 1.0\n  Tree 1 (weight 1.0):\n    If (feature 1 in {1.0})\n     Predict: 1.0\n    Else (feature 1 not in {1.0})\n     If (feature 2 in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n      Predict: 0.0\n     Else (feature 2 not in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n      Predict: 1.0\n  Tree 2 (weight 1.0):\n    If (feature 2 in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n     If (feature 1 in {1.0})\n      If (feature 2 in {10.0})\n       Predict: 0.0\n      Else (feature 2 not in {10.0})\n       Predict: 1.0\n     Else (feature 1 not in {1.0})\n      If (feature 2 in {0.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n       Predict: 0.0\n      Else (feature 2 not in {0.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n       If (feature 2 in {2.0,3.0})\n        Predict: 1.0\n       Else (feature 2 not in {2.0,3.0})\n        Predict: 0.0\n    Else (feature 2 not in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n     Predict: 1.0\n  Tree 3 (weight 1.0):\n    If (feature 2 in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n     If (feature 2 in {5.0,6.0,9.0,10.0,11.0,12.0,13.0})\n      Predict: 0.0\n     Else (feature 2 not in {5.0,6.0,9.0,10.0,11.0,12.0,13.0})\n      If (feature 1 in {1.0})\n       Predict: 1.0\n      Else (feature 1 not in {1.0})\n       If (feature 2 in {7.0,8.0})\n        Predict: 1.0\n       Else (feature 2 not in {7.0,8.0})\n        Predict: 0.0\n    Else (feature 2 not in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n     Predict: 1.0\n  Tree 4 (weight 1.0):\n    If (feature 1 in {1.0})\n     Predict: 1.0\n    Else (feature 1 not in {1.0})\n     If (feature 2 in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n      If (feature 2 in {6.0,10.0,12.0})\n       Predict: 0.0\n      Else (feature 2 not in {6.0,10.0,12.0})\n       If (feature 2 in {13.0})\n        Predict: 1.0\n       Else (feature 2 not in {13.0})\n        Predict: 0.0\n     Else (feature 2 not in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n      Predict: 1.0\n  Tree 5 (weight 1.0):\n    If (feature 2 in {5.0,6.0,9.0,10.0,11.0,12.0,13.0})\n     If (feature 2 in {10.0})\n      Predict: 0.0\n     Else (feature 2 not in {10.0})\n      If (feature 2 in {11.0,12.0,13.0})\n       If (feature 1 in {1.0})\n        Predict: 1.0\n       Else (feature 1 not in {1.0})\n        If (feature 2 in {11.0,12.0})\n         Predict: 0.0\n        Else (feature 2 not in {11.0,12.0})\n         Predict: 1.0\n      Else (feature 2 not in {11.0,12.0,13.0})\n       Predict: 0.0\n    Else (feature 2 not in {5.0,6.0,9.0,10.0,11.0,12.0,13.0})\n     If (feature 2 in {0.0,2.0,3.0,4.0,7.0,8.0})\n      If (feature 1 in {1.0})\n       Predict: 1.0\n      Else (feature 1 not in {1.0})\n       If (feature 2 in {7.0,8.0})\n        Predict: 1.0\n       Else (feature 2 not in {7.0,8.0})\n        Predict: 0.0\n     Else (feature 2 not in {0.0,2.0,3.0,4.0,7.0,8.0})\n      Predict: 1.0\n  Tree 6 (weight 1.0):\n    If (feature 1 in {1.0})\n     Predict: 1.0\n    Else (feature 1 not in {1.0})\n     If (feature 2 in {0.0,2.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n      Predict: 0.0\n     Else (feature 2 not in {0.0,2.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n      Predict: 1.0\n  Tree 7 (weight 1.0):\n    If (feature 2 in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n     If (feature 1 in {1.0})\n      If (feature 2 in {6.0,10.0,12.0})\n       If (feature 2 in {12.0})\n        Predict: 1.0\n       Else (feature 2 not in {12.0})\n        Predict: 0.0\n      Else (feature 2 not in {6.0,10.0,12.0})\n       Predict: 1.0\n     Else (feature 1 not in {1.0})\n      Predict: 0.0\n    Else (feature 2 not in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n     Predict: 1.0\n  Tree 8 (weight 1.0):\n    If (feature 2 in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n     If (feature 2 in {5.0,6.0,9.0,10.0,11.0,12.0,13.0})\n      If (feature 1 in {1.0})\n       If (feature 2 in {12.0})\n        Predict: 1.0\n       Else (feature 2 not in {12.0})\n        Predict: 0.0\n      Else (feature 1 not in {1.0})\n       Predict: 0.0\n     Else (feature 2 not in {5.0,6.0,9.0,10.0,11.0,12.0,13.0})\n      If (feature 1 in {0.0})\n       Predict: 0.0\n      Else (feature 1 not in {0.0})\n       Predict: 1.0\n    Else (feature 2 not in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n     Predict: 1.0\n  Tree 9 (weight 1.0):\n    If (feature 2 in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n     If (feature 2 in {5.0,6.0,9.0,10.0,11.0,12.0,13.0})\n      If (feature 2 in {13.0})\n       Predict: 1.0\n      Else (feature 2 not in {13.0})\n       If (feature 2 in {10.0,11.0})\n        Predict: 0.0\n       Else (feature 2 not in {10.0,11.0})\n        If (feature 2 in {12.0})\n         Predict: 1.0\n        Else (feature 2 not in {12.0})\n         Predict: 0.0\n     Else (feature 2 not in {5.0,6.0,9.0,10.0,11.0,12.0,13.0})\n      If (feature 1 in {1.0})\n       Predict: 1.0\n      Else (feature 1 not in {1.0})\n       Predict: 0.0\n    Else (feature 2 not in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n     Predict: 1.0\n  Tree 10 (weight 1.0):\n    If (feature 2 in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n     If (feature 2 in {5.0,6.0,9.0,10.0,11.0,12.0,13.0})\n      If (feature 2 in {10.0})\n       Predict: 0.0\n      Else (feature 2 not in {10.0})\n       If (feature 2 in {11.0,12.0,13.0})\n        If (feature 2 in {11.0})\n         Predict: 0.0\n        Else (feature 2 not in {11.0})\n         Predict: 1.0\n       Else (feature 2 not in {11.0,12.0,13.0})\n        Predict: 0.0\n     Else (feature 2 not in {5.0,6.0,9.0,10.0,11.0,12.0,13.0})\n      If (feature 2 in {7.0,8.0})\n       Predict: 1.0\n      Else (feature 2 not in {7.0,8.0})\n       If (feature 2 in {4.0})\n        Predict: 0.0\n       Else (feature 2 not in {4.0})\n        If (feature 1 in {0.0})\n         Predict: 0.0\n        Else (feature 1 not in {0.0})\n         Predict: 1.0\n    Else (feature 2 not in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n     Predict: 1.0\n  Tree 11 (weight 1.0):\n    If (feature 2 in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n     If (feature 1 in {1.0})\n      If (feature 2 in {6.0,10.0,12.0})\n       If (feature 2 in {12.0})\n        Predict: 1.0\n       Else (feature 2 not in {12.0})\n        Predict: 0.0\n      Else (feature 2 not in {6.0,10.0,12.0})\n       Predict: 1.0\n     Else (feature 1 not in {1.0})\n      If (feature 2 in {0.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n       Predict: 0.0\n      Else (feature 2 not in {0.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n       If (feature 2 in {2.0,3.0})\n        Predict: 1.0\n       Else (feature 2 not in {2.0,3.0})\n        Predict: 0.0\n    Else (feature 2 not in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n     Predict: 1.0\n  Tree 12 (weight 1.0):\n    If (feature 2 in {4.0,5.0,6.0,8.0,9.0,10.0,11.0,12.0,13.0})\n     If (feature 1 in {1.0})\n      If (feature 2 in {6.0,10.0,12.0})\n       Predict: 0.0\n      Else (feature 2 not in {6.0,10.0,12.0})\n       Predict: 1.0\n     Else (feature 1 not in {1.0})\n      Predict: 0.0\n    Else (feature 2 not in {4.0,5.0,6.0,8.0,9.0,10.0,11.0,12.0,13.0})\n     If (feature 2 in {0.0,2.0,3.0,7.0})\n      If (feature 1 in {0.0})\n       Predict: 0.0\n      Else (feature 1 not in {0.0})\n       Predict: 1.0\n     Else (feature 2 not in {0.0,2.0,3.0,7.0})\n      Predict: 1.0\n  Tree 13 (weight 1.0):\n    If (feature 1 in {1.0})\n     Predict: 1.0\n    Else (feature 1 not in {1.0})\n     If (feature 2 in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n      Predict: 0.0\n     Else (feature 2 not in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n      Predict: 1.0\n  Tree 14 (weight 1.0):\n    If (feature 1 in {1.0})\n     Predict: 1.0\n    Else (feature 1 not in {1.0})\n     Predict: 0.0\n  Tree 15 (weight 1.0):\n    If (feature 1 in {1.0})\n     Predict: 1.0\n    Else (feature 1 not in {1.0})\n     If (feature 2 in {0.0,2.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n      If (feature 2 in {10.0})\n       Predict: 0.0\n      Else (feature 2 not in {10.0})\n       If (feature 2 in {6.0,7.0,8.0,11.0,12.0,13.0})\n        If (feature 2 in {6.0,11.0,12.0,13.0})\n         Predict: 0.0\n        Else (feature 2 not in {6.0,11.0,12.0,13.0})\n         Predict: 1.0\n       Else (feature 2 not in {6.0,7.0,8.0,11.0,12.0,13.0})\n        Predict: 0.0\n     Else (feature 2 not in {0.0,2.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n      Predict: 1.0\n  Tree 16 (weight 1.0):\n    If (feature 2 in {5.0,6.0,9.0,10.0,11.0,12.0,13.0})\n     Predict: 0.0\n    Else (feature 2 not in {5.0,6.0,9.0,10.0,11.0,12.0,13.0})\n     If (feature 2 in {0.0,2.0,3.0,4.0,7.0,8.0})\n      If (feature 1 in {0.0})\n       If (feature 2 in {7.0,8.0})\n        Predict: 1.0\n       Else (feature 2 not in {7.0,8.0})\n        Predict: 0.0\n      Else (feature 1 not in {0.0})\n       Predict: 1.0\n     Else (feature 2 not in {0.0,2.0,3.0,4.0,7.0,8.0})\n      Predict: 1.0\n  Tree 17 (weight 1.0):\n    If (feature 2 in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n     If (feature 2 in {5.0,6.0,9.0,10.0,11.0,12.0,13.0})\n      If (feature 2 in {10.0})\n       Predict: 0.0\n      Else (feature 2 not in {10.0})\n       If (feature 1 in {1.0})\n        If (feature 2 in {12.0})\n         Predict: 1.0\n        Else (feature 2 not in {12.0})\n         Predict: 0.0\n       Else (feature 1 not in {1.0})\n        Predict: 0.0\n     Else (feature 2 not in {5.0,6.0,9.0,10.0,11.0,12.0,13.0})\n      If (feature 2 in {7.0,8.0})\n       Predict: 1.0\n      Else (feature 2 not in {7.0,8.0})\n       If (feature 1 in {0.0})\n        Predict: 0.0\n       Else (feature 1 not in {0.0})\n        Predict: 1.0\n    Else (feature 2 not in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n     Predict: 1.0\n  Tree 18 (weight 1.0):\n    If (feature 2 in {5.0,6.0,9.0,10.0,11.0,12.0,13.0})\n     If (feature 1 in {1.0})\n      If (feature 2 in {12.0})\n       Predict: 1.0\n      Else (feature 2 not in {12.0})\n       Predict: 0.0\n     Else (feature 1 not in {1.0})\n      Predict: 0.0\n    Else (feature 2 not in {5.0,6.0,9.0,10.0,11.0,12.0,13.0})\n     If (feature 1 in {1.0})\n      Predict: 1.0\n     Else (feature 1 not in {1.0})\n      If (feature 2 in {0.0,2.0,3.0,4.0,7.0,8.0})\n       If (feature 2 in {7.0,8.0})\n        Predict: 1.0\n       Else (feature 2 not in {7.0,8.0})\n        Predict: 0.0\n      Else (feature 2 not in {0.0,2.0,3.0,4.0,7.0,8.0})\n       Predict: 1.0\n  Tree 19 (weight 1.0):\n    If (feature 2 in {4.0,5.0,6.0,8.0,9.0,10.0,11.0,12.0,13.0})\n     If (feature 2 in {10.0,11.0})\n      Predict: 0.0\n     Else (feature 2 not in {10.0,11.0})\n      If (feature 2 in {12.0,13.0})\n       Predict: 1.0\n      Else (feature 2 not in {12.0,13.0})\n       If (feature 1 in {1.0})\n        If (feature 2 in {8.0})\n         Predict: 1.0\n        Else (feature 2 not in {8.0})\n         Predict: 0.0\n       Else (feature 1 not in {1.0})\n        Predict: 0.0\n    Else (feature 2 not in {4.0,5.0,6.0,8.0,9.0,10.0,11.0,12.0,13.0})\n     If (feature 2 in {0.0,2.0,3.0,7.0})\n      If (feature 2 in {3.0,7.0})\n       Predict: 1.0\n      Else (feature 2 not in {3.0,7.0})\n       If (feature 2 in {2.0})\n        Predict: 1.0\n       Else (feature 2 not in {2.0})\n        If (feature 1 in {0.0})\n         Predict: 0.0\n        Else (feature 1 not in {0.0})\n         Predict: 1.0\n     Else (feature 2 not in {0.0,2.0,3.0,7.0})\n      Predict: 1.0\n\n"
     ]
    }
   ],
   "source": [
    "# We can check the output in the same way\n",
    "rfModel = pipelineModel.stages[-1]\n",
    "print(rfModel.toDebugString)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Binary Classification with Decision Trees and Random Forests",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
